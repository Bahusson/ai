{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model wyżyłowany przeze mnie\n",
    "W tym modelu nie znajdziesz typowych komentarzy szkoleniowych, a jedynie krótki opis służący nawigacji po modelu.\n",
    "Jeśli masz potrzebę zrozumieć jak działa w szczególe, przejrzyj zeszyty ćwiczeń 1-3, oraz zeszyty badawcze.\n",
    "To jest synteza dotychczasowych prac. Jeśli nie rozumiesz kodu pythonowskiego, to polecam StackOverflow, chociaż zawsze staram się aby był w miarę prosty i zrozumiały. Konkludując: baw się dobrze. :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import mnistworkaround\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = mnistworkaround.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinker import RangeDict # - Jeśli chcesz używać ciągów różnych ukrytych warstw o tej samej \"grubości\"\n",
    "                    # to zdejmij komentarz z tego importu i zmień h_lay_diff na odpowiadające Ci wartości.\n",
    "                    # Oczywiście jak robisz z tego GUI, to zdejmij go permanentnie i \"zamroź\" do wersji maksimum.\n",
    "from tinker import HLayer      # - W trakcie tworzenia automat do tworzenia\n",
    "                               # kolejnych warstw za pomocą tej klasy. Na razie nie ma szans, żeby działała... ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PANEL GŁÓWNY ###\n",
    "\n",
    "l_rate = 0.001          # Prędkość uczenia się modelu. Domyślna: 0.001\n",
    "s_batches = 100         # Wielkość partii w jakich uczymy model (batch_size)\n",
    "n_epochs = 15           # Górne organiczenie ilości \"epok\"\n",
    "hlay_size = 50          # Domyślny rozmiar każdej ukrytej warstwy \"neuronów\" dla której nie postanowisz inaczej.\n",
    "\n",
    "\n",
    "# Eksperymentalne zmienne dla nowego importu, nad którym pracuję w celu ułatwienia sobie i innym pracy.\n",
    "# Chwilowo nic nie robi, ale mam nadzieję, że wkrótce będzie. :D\n",
    "hlay_num = 2          # Definiuje ilość ukrytych warstw (Domyślnie: 2)\n",
    "hlay_diff = {}        # Jeśli zdecydujesz się używać innych wartości dla różnych warstw, to wrzuć tu w formacie {1 : 30, 9 : 70} \n",
    "                        # itp. funkcja zaczerpnie stąd wartość, a jeśli jej nie zdefiniujesz, to użyje domyślnej.\n",
    "                        # przy dłuższych ciągach możesz użyć \"tinker.RangeDict({})\", żeby ułatwić sobie życie.\n",
    "                        # po prostu zmień zwyczajne nawiasy na ww funkcję i zdejmij komentarz z importu RangeDict.\n",
    "\n",
    "# Tego nie rusz, chyba, że masz inne rozmiary obrazka grayscale, albo w ogóle zmieniłeś rodzaj inputu, np. na kolorowy RGBA:\n",
    "input_size = 784        # Rozmiar danych wejściowych to 784, gdyż rozmiar obrazka w bazie danych MNIST to 28x28px=784px.\n",
    "output_size = 10        # Rozmiar danych wyjściowych to 10, gdyż baza danych MNIST zawiera 10 cyfr od 0 do 9\n",
    "\n",
    "\n",
    "tf.reset_default_graph() # Resetuje zmienne zapisane w pamięci modelu z jego poprzednich przebiegów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawniki dla danych wejściowych i celów.\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "targets = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "# Wagi łączące pierwszą warstwę \"inputs\" z 1 warstwą \"ukrytą\"\n",
    "weights_1 = tf.get_variable(\"weights_1\", [input_size, hlay_size])\n",
    "biases_1 = tf.get_variable(\"biases_1\", [hlay_size])\n",
    "outputs_1 = tf.nn.relu(tf.matmul(inputs, weights_1) + biases_1)\n",
    "\n",
    "# Wagi i obciążenia łączące warstwę ukrytą 1 z warstwą ukrytą 2. Do automatyzacji na panelu.\n",
    "weights_2 = tf.get_variable(\"weights_2\",[hidden_layer_size, hidden_layer_size])\n",
    "biases_2 = tf.get_variable(\"biases_2\",[hidden_layer_size])\n",
    "# Zwróć uwagę z czego zwracamy wynik outputs_2, czyli wynik aktywacji drugiej warstwy.\n",
    "outputs_2 = tf.nn.relu(tf.matmul(outputs_1, weights_2) + biases_2)\n",
    "\n",
    "# Wagi łączące ostatnią warstwę ukrytą z warstwą danych wyjściowych (outputs).\n",
    "weights_3 = tf.get_variable(\"weights_3\", [hidden_layer_size, output_size])\n",
    "biases_3 = tf.get_variable(\"biases_3\", [output_size])\n",
    "\n",
    "# Zwróć uwagę, że nie zwróciliśmy tutaj od razu funkcji aktywacyjnej, a jedynie iloczyn skalarny + obciążenie 3.\n",
    "\n",
    "outputs = tf.matmul(outputs_2, weights_3) + biases_3\n",
    "\n",
    "# Poniższa funkcja aplikuje zarówno Aktywator Softmax, który jest wskazany przy danych wyjściowych\n",
    "# (bo daje wyskalowane przedziały ufności dzielone przez dostępne opcje sumarycznie do 1)\n",
    "# oraz aplikuje koszt z funkcji logarytmicznej liczony od całkowitego błędu. \n",
    "# Format użycia to: tf.nn.softmax_cross_entropy_with_logits(logits,labels) Tutaj: logits = wyjściowe, labels = cele (targets)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets)\n",
    "\n",
    "# Poniższa metoda poprawia nam osiągi. W tej sposób TF szuka nam średnią elementów tensora w danym wymiarze.\n",
    "# Więcej o zastosowaniu ENG tutaj*\n",
    "mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "# Wybieramy model treningowy. Ponieważ poszliśmy do przodu z teorią, to tym razem wybierzemy sobie ADAM,\n",
    "# który jest o tyle dobry, że raczej nie zacina się na lokalnym (fałszywym) minimum funkcji i optymalnie szuka\n",
    "# globalnego minimum. Jest to metoda z 2015, więc dość nowa. Daj mi znać jeśli wymyślono coś lepszego.\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(mean_loss)\n",
    "\n",
    "# Metoda tf.argmax pozwala nam wybrać która zmienna ma najwyższy \"wynik\" (patrz niżej) zwracany przez funkcję w sposób: \n",
    "# (outputs: z aktywatora softmax, tj. tutaj model próbuje \"zgadnąć\" prawidłowy wynik o który nam chodzi,\n",
    "# przydzielając poszczególnym zmiennym prawdopodobieństwo. Agrmax wybiera najwyższe prawdopodobieństwo.)\n",
    "# (targets: zdefiniowane przez nas w ramach bazy \"labels\", do czego dąży model. \n",
    "# W wypadku \"OneHot\" tylko jedna zmienna będzie miała wartość 1 a pozostałe 0 i to ją wybierze Argmax.)\n",
    "# tf.equal (bool) porównuje te dwa ciągi, które zwracają argmax i jeśli się pokrywają zwraca 1 a jeśli nie 0.\n",
    "# Otrzymujemy więc wektor zero-jedynkowy, który nabierze sensu w ramach kolejnej funkcji...\n",
    "out_equals_target = tf.equal(tf.argmax(outputs,1), tf.argmax(targets,1))\n",
    "\n",
    "# tf.reduce_mean*, o którym możesz poczytać poniżej pozwala nam logicznie obliczyć trafność modelu.\n",
    "# Po prostu bierze wszystkie te 0 (nietrafione) i 1 (trafione decyzje modelu) i wyciąga średnią. Oto nasza trafność.:)\n",
    "# tf.cast(obiekt_do_konwersji, docelowy_format) to nasze ubezpieczenie, na wszelki wypadek\n",
    "# aby dane, które zwróci nam funkcja na pewno były w odpowiednim formacie. (tutaj tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(out_equals_target, tf.float32))\n",
    "\n",
    "# Odpalamy sesję i inicjalizujemy zmienne w ramach sesji. Szczegóły w zeszycie 2, pkt 5 i 6.\n",
    "sess = tf.InteractiveSession()\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "\n",
    "# Wielkość pakietów. Zdecyduj o wielkości pakietów na które będzie dzielona baza treningowa.\n",
    "# Tzn. jak często model będzie poprawiał swoje wagi i obciążenia.\n",
    "# Jeśli wpiszesz ilość równą ilości obserwacji (niezalecane)\n",
    "# model przejdzie w ramach 1 epoki na raz przez całą bazę danych i będzie najdokładniejszy \n",
    "# (przykład: \"Gradient Descent\"), ale jest to bardzo zasobochłonne\n",
    "# Im mniejszy pakiet względem bazy danych, tym częstsza aktualizacja w ramach przechodzenia przez nią,\n",
    "# ale mniejsza dokładność (Jak w Stochastic Gradient Descent).\n",
    "# Ogólnie warto się z tym pobawić i raczej na ogół warto poświęcić trochę dokładności na rzecz szybkości.\n",
    "# Startowa : 100 mówi, że w ramach jednego \"przejścia\" przez bazę, \n",
    "# wagi i średnie zostaną dostosowane (ilość_przykładów / 100 razy). \n",
    "# Dzielenie \"floordiv\" zaokrągla ilość do równej wartości. // Edit: Wyciągnięta na panel główny.\n",
    "batch_size = s_batches\n",
    "# Ta zmienna to wynik dzielenia liczby przykładów treningowych w bazie danych przez rozmiar partii.\n",
    "batches_number = mnist.train._num_examples // batch_size\n",
    "\n",
    "# Poniżej dwa mechanizmy zatrzymujące:\n",
    "# Ta zmienna ogranicza z góry liczbę \"przejść\" przez bazę, tak aby model się nie zaciął. // Edit: Wyciągnięta na panel główny.\n",
    "max_epochs = n_epochs\n",
    "# Ta zmienna da nam pewność, że model nie przerwie działania po pierwszym przebiegu (epoce).\n",
    "# Model porównuje wyniki treningowe do bazy walidacyjnej i sprawdza, czy nie zaszło tzw. overfitting (naddopasowanie modelu)\n",
    "# Wysoka wartość poprzedniej straty z walidacj przeciwdziała tutaj przerwaniu po pierwszej epoce,\n",
    "# gdyż na początku model takowej wartości nie ma, więc domyślne 0 spowodowałoby niewłaściwe przerwanie, co mija się z celem...\n",
    "prev_validation_loss = 9999999.\n",
    "\n",
    "# Podobną pętlę masz w zeszycie 2. Jak coś jest niejasne sprawdź tam, bo staram się nie powtarzać.\n",
    "# W tym miejscu odbywa się uczenie modelu. Zauważ, że ta pętla nie przebiegnie więcej niż 15 razy.\n",
    "for epoch_counter in range(max_epochs):\n",
    "    \n",
    "    # Ustalamy zmienną do której pętla zapisuje obecną wartość funkcji straty.\n",
    "    curr_epoch_loss = 0.\n",
    "    \n",
    "    # Pętla kręci się do wykorzystania wszystkich partii.\n",
    "    for batch_counter in range(batches_number):\n",
    "        \n",
    "        # Tutaj pętla ładuje [100] wejść (input_batch) i [100] celów (target_batch) ([100] wynika z \"batch_size\")\n",
    "        input_batch, target_batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # Tutaj optymalizuje algorytm i kalkuluje funkcję straty dla każdej partii. \n",
    "        _, batch_loss = sess.run([optimize, mean_loss], \n",
    "            feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        \n",
    "        # Tutaj zapisuje stratę dla obecnej iteracji pętli\n",
    "        curr_epoch_loss += batch_loss\n",
    "    \n",
    "    # Teraz zmienna curr_epoch_loss faktycznie zawiera średnią wartość funkcji straty dla zestawu treningowego\n",
    "    # dla kolejnej epoki. Otrzymujemy ją dzieląc sumę strat ze wszystkich partii w epoce przez liczbę partii.\n",
    "    curr_epoch_loss /= batches_number\n",
    "\n",
    "    # Tutaj ładujemy zestaw walidacyjny wyodrębiony już dla nas w paczce MNIST. Ten zestaw wykorzystujemy\n",
    "    # wielokrotnie, i podlega on jedynie propagacji w przód, tzn. nie dostosowujemy do niego wag modelu\n",
    "    # (nie trenujemy na nim). Dzieje się tak dlatego, że względem tej małej próbki (zwykle ok 10% bd)\n",
    "    # sprawdzamy, czy nie zaszło naddopasowanie (overfitting).\n",
    "    input_batch, target_batch = mnist.validation.next_batch(mnist.validation._num_examples)\n",
    "    \n",
    "    \n",
    "    # Oblicza średnią stratę i trafność zestawu walidacyjnego i zapisuje je w odpowiadających im zmiennych\n",
    "    validation_loss, validation_accuracy = sess.run([mean_loss, accuracy], \n",
    "                                                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "    \n",
    "    # Zwraca nam w widoczny sposób wartości zmiennych dla każdej 'Epoki'. Formatowanie typowo pythonowskie.\n",
    "    print('Epoka: '+str(epoch_counter+1)+\n",
    "          '. Strata z Treningu : '+'{0:.3f}'.format(curr_epoch_loss)+\n",
    "          '. Strata z Walidacji: '+'{0:.3f}'.format(validation_loss)+\n",
    "          '. Trafność Walidacji: '+'{0:.2f}'.format(validation_accuracy * 100)+'%')\n",
    "    \n",
    "    # Przerywa pętlę wcześniej jeśli strata z walidacji zacznie wzrastać wskazując na naddopasowanie modelu.\n",
    "    if validation_loss > prev_validation_loss:\n",
    "        break\n",
    "        \n",
    "    # Aktualizuje stratę z walidacji, żeby ją można było porównać po każdej epoce.    \n",
    "    prev_validation_loss = validation_loss\n",
    "        \n",
    "print(\"Koniec Sesji Treningowej\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
