{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sekwencyjny model CNN z Keras i własną Bazą Danych\n",
    "W tym zeszycie używam własnej, przygotowanej wcześniej bazy obrazków do analizy.\n",
    "Obrazki mogą być w dowolnym formacie, ale z przyzwyczajenia użyłem takiego samego jak w MNIST.\n",
    "Tym razem jednak są w formacie PNG (mogą być i JPG), w skali szarości i ich procesowanie wyglądało nieco inaczej.\n",
    "Jak przygotować zbiór danych piszę poniżej:\n",
    "\n",
    "<Tu wstaw opis jak przygotowałeś zbiór danych jak już kod będzie działał poprawnie>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Poniższy model daje nam jako takie pojęcie o tym w jaki sposób można przygotować niewielką ilość danych tak,\n",
    "# aby model jednak się czegoś nauczył. W końcu nie zawsze mamy jakieś pół miliona rekordów. Ja dostałem powalającą\n",
    "# ilość 150 case'ów ćwiczebnych, także trzeba było kombinować. Poniżej masz rezultat mojego bezczelnego zżyniania,\n",
    "# optymalizowania i kombinowania. Enjoy. :P\n",
    "\n",
    "# Oryginalny kod pożyczony w słusznej sprawie z: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "#from keras.optimizers import SGD #Używam Adam, ale mogę chcieć użyć np. SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Podajemy wymiary obrazka. Ja używam formatu takiego jak w MNIST, ale możesz mieć każdy inny...\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "num_classes = 10 # Ilość kategorii\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 150\n",
    "nb_validation_samples = 80\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "color_cha = 1 # Ilość kanałów. W Odcieniach szarości będziesz miał 1, W kolorze (RGB) będziesz miał 3.\n",
    "\n",
    "# Ten fragment odczytuje z obrazków w jakim formacie są zapisane kanały kodowania kolorów.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (color_cha, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, color_cha)\n",
    "\n",
    "# Część główna modelu. W porównaniu do TF, Keras jest bardzo prosty. \n",
    "# Jak klocki lego układa się warstwa na warstwie.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), # Tutaj kernel = filtr. Tj. 'przesuwamy' tym naszym filtrem o kształcie 3x3 po obrazku.\n",
    "                                         # Poczytaj albo najlepiej obejrzyj film o CNN, bo to trudno opisać słowami.:)\n",
    "                                         # Sprowadza się to do wyciągnięcia z tego 'przesuwania' kolejnej macierzy z Iloczynem Skalarnym.\n",
    "                                         # W ten sposób można znaleźć 'interesujące', tj. kluczowe elementy obrazka i zaoszczędzić\n",
    "                                         # na mocy obliczeniowej, oraz godzinach pracy przy ręcznym obrabianiu baz danych... Ale naprawdę obejrzyj wizualizację. Warto.\n",
    "                 activation='relu',  # Wszyscy raczej zgadzają się, że Relu w warstwach ukrytych jest najpopularniejszy do aktywacji, bo przyspiesza uczenie.\n",
    "                 input_shape=input_shape))\n",
    "# Tutaj zauważ zmianę względem poprzedniego modelu.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) # W następnym już nie definiuję słownie kernel_size = (x,y), ale wiadomo ocb.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) # Pokombinuj z wartościami 'dropout'. Raczej zaczynaj od mniejszych i zwiększaj z czasem.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5)) # Nie dawaj wyższych wartości końcowych 'dropout' niż 0.5, chyba, że wiesz co robisz...\n",
    "# Sposób aktywacji ostatniej warstwy inny niż na przykładzie wyjściowym, \n",
    "# bo mam 10 kategorii, więc lepiej wziąć softmax.\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "                    # Sposób kalkulowania straty. Inny niż w przykładzie z którego brałem kod, bo mam aż 10 kategorii.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #Tutaj warto poeksperymentować z metodą optymalizacji:\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 10 classes.\n",
      "Found 80 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 2.0568 - acc: 0.3309 - val_loss: 1.2813 - val_acc: 0.7455\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 1.1883 - acc: 0.5967 - val_loss: 0.5741 - val_acc: 0.8462\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.6283 - acc: 0.7969 - val_loss: 0.2542 - val_acc: 0.9375\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.4894 - acc: 0.8316 - val_loss: 0.1734 - val_acc: 0.9777\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 3s 195ms/step - loss: 0.4023 - acc: 0.8668 - val_loss: 0.1071 - val_acc: 0.9663\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.3025 - acc: 0.9110 - val_loss: 0.0871 - val_acc: 0.9760\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.2989 - acc: 0.9152 - val_loss: 0.0620 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 3s 216ms/step - loss: 0.1694 - acc: 0.9426 - val_loss: 0.0418 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1453 - acc: 0.9677 - val_loss: 0.0386 - val_acc: 0.9856\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.1553 - acc: 0.9424 - val_loss: 0.0413 - val_acc: 0.9866\n"
     ]
    }
   ],
   "source": [
    "### Preprocesowanie obrazków z TF Keras: https://keras.io/preprocessing/image/ ###\n",
    "\n",
    "# Deklarujemy chęć używania TensorBoard jako narzędzia wizualizacyjnego.\n",
    "tb_callback1 = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "# Wybieramy callbacki i dodajemy do listy jak w dokumentacji: https://keras.io/callbacks/#tensorboard\n",
    "callbacks = []\n",
    "callbacks.append(tb_callback1)\n",
    "\n",
    "# Konfiguracja preprocesująca, której używamy do treningu.\n",
    "train_datagen = ImageDataGenerator(\n",
    "# obowiązkowe przeskalowanie (Normalizacja) z obowiązkowej skali int 0-225 na float32 0-1\n",
    "    rescale = 1. / 255,\n",
    "    rotation_range = 4, # W stopniach. Losowo obraca obrazki o tyle stopni.\n",
    "    # Przycięcie obrazka do wartości zbliżenia.\n",
    "     shear_range = 0.2,\n",
    "    # Powiększenie obrazka o wartość przycięcia.\n",
    "    zoom_range = 0.2,\n",
    "    )\n",
    "# Jakbyśmy mieli np. obrazki psów i kotów, albo samochodów, to można je jeszcze np. przerzucić w pionie. \n",
    "# W wypadku pewnych zbiorów danych jak np. litery, cyfry itp. znaki, to jest imho wątpliwe ;)\n",
    "# Kod przerzucający poniżej: horizontal_flip=True. Wrzuć wraz z resztą w nawias. \n",
    "# Więcej i pomocy tricków znajdziesz w Zakładce ImageDataGenerator w linku u góry.\n",
    "# Jak to odpowiednio rozbujać, to wygląda jakbyśmy chcieli zafundować maszynie halucynacje... :]\n",
    "\n",
    "# Konfiguracja preprocesująca, której użyjemy do walidacji i testów:\n",
    "# Tylko przeskalowanie nasycenia z int na float.\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',  # Obrazki są w skali szarości. Jak tego nie damy, to model przyjmie, że są w RGB.\n",
    "    class_mode='categorical') # Typ klasyfikacji. Tutaj zwraca nam 10 typu one-hot.\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks)\n",
    "    \n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.046829879427185424 Accuracy:  0%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, nb_validation_samples/batch_size, workers=12)\n",
    "print(\"Loss: \", score[0], \"Accuracy: \", str(int(score[1])*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja uczenia się modelu\n",
    "Zobaczymy czy, na ile i w którym miejscu mamy overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label='Validation/Test Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label='Training loss')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Poniżej funkcja straty w czasie dla powyższego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_acc_values, label='Validation/Test Accuracy')\n",
    "line2 = plt.plot(epochs, acc_values, label='Training Accuracy')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Poniżej trafność w czasie dla powyższego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisujemy nasz model\n",
    "Zmień na pełną ścieżkę docelową na swoim komputerze.\n",
    "Uważaj, żeby folder faktycznie istniał, bo program nie stworzy ścieżek automatycznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model.save(\"/home/SpookyProgrammer/tensorxp/git/ai/research_process/trainedmodels/simple_chars_10c.h5\")\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytujemy model\n",
    "To trochę bardziej skomplikowane, bo Keras musi teraz wszystko rozpakować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('/home/SpookyProgrammer/tensorxp/git/ai/research_process/trainedmodels/simple_chars_10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja Sieci (Matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "num_classes = 10 # Ilość kategorii\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 150\n",
    "nb_validation_samples = 80\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "color_cha = 1 # Ilość kanałów. W Odcieniach szarości będziesz miał 1, W kolorze (RGB) będziesz miał 3.\n",
    "\n",
    "# Ten fragment odczytuje z obrazków w jakim formacie są zapisane kanały kodowania kolorów.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (color_cha, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, color_cha)\n",
    "\n",
    "# Część główna modelu. W porównaniu do TF, Keras jest bardzo prosty. \n",
    "# Jak klocki lego układa się warstwa na warstwie.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), # Tutaj kernel = filtr. Tj. 'przesuwamy' tym naszym filtrem o kształcie 3x3 po obrazku.\n",
    "                                         # Poczytaj albo najlepiej obejrzyj film o CNN, bo to trudno opisać słowami.:)\n",
    "                                         # Sprowadza się to do wyciągnięcia z tego 'przesuwania' kolejnej macierzy z Iloczynem Skalarnym.\n",
    "                                         # W ten sposób można znaleźć 'interesujące', tj. kluczowe elementy obrazka i zaoszczędzić\n",
    "                                         # na mocy obliczeniowej, oraz godzinach pracy przy ręcznym obrabianiu baz danych... Ale naprawdę obejrzyj wizualizację. Warto.\n",
    "                 activation='relu',  # Wszyscy raczej zgadzają się, że Relu w warstwach ukrytych jest najpopularniejszy do aktywacji, bo przyspiesza uczenie.\n",
    "                 input_shape=input_shape))\n",
    "# Tutaj zauważ zmianę względem poprzedniego modelu.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) # W następnym już nie definiuję słownie kernel_size = (x,y), ale wiadomo ocb.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25)) # Pokombinuj z wartościami 'dropout'. Raczej zaczynaj od mniejszych i zwiększaj z czasem.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5)) # Nie dawaj wyższych wartości końcowych 'dropout' niż 0.5, chyba, że wiesz co robisz...\n",
    "# Sposób aktywacji ostatniej warstwy inny niż na przykładzie wyjściowym, \n",
    "# bo mam 10 kategorii, więc lepiej wziąć softmax.\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "                    # Sposób kalkulowania straty. Inny niż w przykładzie z którego brałem kod, bo mam aż 10 kategorii.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #Tutaj warto poeksperymentować z metodą optymalizacji:\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz mi wizualizację diagramu modelu w tym miejscu:\n",
    "model_diagrams_path = '/home/SpookyProgrammer/tensorxp/git/ai/research_process/trainedmodels/'\n",
    "\n",
    "#Wygeneruj mi diagram:\n",
    "plot_model(model, to_file = model_diagrams_path + 'schemat_modelu_10_liter.png',\n",
    "          show_shapes = True,\n",
    "          show_layer_names = True)\n",
    "\n",
    "#Pokaż go poniżej:\n",
    "img = mpimg.imread(model_diagrams_path + 'schemat_modelu_10_liter.png')\n",
    "plt.figure(figsize=(30,15))\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
