{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PANEL GŁÓWNY Numpy ### - Zmienne niezbędne dla wykonania zbioru danych przez Numpy biorą się stąd. \n",
    "# Szczegóły słabiej opisanych - zeszyt kursowy 1\n",
    "\n",
    "observations = 1000  # Ustaw ilość obserwacji (Startowa: 1000)\n",
    "vnum = 1             # Liczba zmiennych\n",
    "noic = 10            # Szum w bazie przypadków treningowych.\n",
    "noit = 1             # Szum wygenerowany dla funkcji testującej (docelowej).\n",
    "model = [13,7,-12]   # Parametry modelu losowego dla funkcji a*xs + b*xz + c + szum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tworzenie i składowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.uniform(low = -noic, high = noic, size =(observations,vnum)) # Gen. zakr. los. zm. wej.(patrz zeszyt 1)\n",
    "zs = np.random.uniform(-noic,noic,(observations,vnum)) # J.w.- bez opisów bo zbędne. Poz. dla orientacji.\n",
    "\n",
    "generated_inputs = np.column_stack((xs,zs)) # Składanie z pow. matrycy w formacie observationsx2. (Patrz zeszyt 1)\n",
    "\n",
    "noise = np.random.uniform(-noit,noit,(observations,1)) # Gen. zakr. los. (Patrz zeszyt 1)\n",
    "\n",
    "generated_targets = model[0]*xs + model[1]*zs + model[2] + noise # Funkcja symulująca zadane cele. Do niej dąży model. (Patrz zeszyt 1)\n",
    "\n",
    "np.savez('My_Nums', inputs = generated_inputs, targets = generated_targets) # Tworzy plik My_Nums.npz w tym samym miejscu co ten zeszyt. \n",
    "# Zawiera podane matryce w formie ndarray, co dla obsługi TF jest bardzo wygodne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tutaj zaczyna się TensorFlow\n",
    "Uwaga odnośnie używania TF - obiekty TF nie wykonują się same.\n",
    "Trzeba im wydać konkretne polecenie. \n",
    "\n",
    "Jeśli chcesz na to spojrzeć z innej strony, \n",
    "to zeszyt badawczy 2a zawiera opis i przykłady poszczególnych elementów TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Panel Główny TF ### - tutaj będę wyciągał zmienne dla modelu TF,\n",
    "# żeby było jasne co jest do czego. Normalnie wszystkie zmienne,\n",
    "# którymi miałbym potencjalnie poźniej manipulować zbieram dla porządku 1 miejscu.\n",
    "\n",
    "input_size = 2       # Ilość zmiennych wejściowych - tutaj mamy dwie (x,z)\n",
    "output_size = 1      # Nasza funkcja ma jedno wyjście - y.\n",
    "iterations = 100     # Wyciągnięta na panel ilość iteracji. Zasada jak w zeszycie 1. (Startowa: 100)\n",
    "lr = 0.02            # Ustaw prędkość uczenia się (Startowa 0.02)\n",
    "loss_switch = True   # Przełącznik funkcji celowej. Jeśli True to Euklidesowa, jeśli False, Hubera. (patrz pkt. 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Rysujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzy podstawnik do którego będziemy podstawiać dane wejściowe z naszego zbioru danych w pliku npz.\n",
    "# 'float32' to miara precyzji (32bit) - standard dla Pythona to float64, ale tyle na ogół wystarczy.\n",
    "# W nawiasie kwadratowym znajdują się wymiary podstawianych matryc. 'None' jest w pierwszym nie dlatego,\n",
    "# że nasze dane nie mają pierwszego wymiaru (tj. ilość rekordów), ale że nie musimy tego określać.\n",
    "# To przydatne, bo nie trzeba dzięki temu znać dokładnej ilości obserwacji ani pisać odpowiedniego kodu samemu.\n",
    "# Ważne jedynie, żeby podać ilość zmiennych wejściowych (input_size) i wyjściowych (output_size).\n",
    "inputs = tf.placeholder(tf.float32,[None,input_size])\n",
    "# Podstawnik gdzie podamy funkcji dane testowe (cele) - jest w tym samym kształcie co dane wyjściowe,\n",
    "# więc korzystamy ze zmiennej opisującej ilość zmiennych wyjściowych (output_size).\n",
    "targets = tf.placeholder(tf.float32,[None,output_size])\n",
    "\n",
    "### To były podstawniki. Zauważ, że pomiędzy iteracjami nie zachowują one swojej wartości. Są one dla TF\n",
    "### tymczasową zmienną zewnętrzną z której czerpie dane. Do dalszego działania będziemy potrzebować zmiennych.\n",
    "### Zwróć uwagę gdzie w TensorFlow są wielkie litery jak na przykład w tf.Variable. To Ci oszczędzi stresów.\n",
    "\n",
    "# Tworzymy zmienne gdzie model będzie zwracał Wagi (weights) i Obciążenia (biases). Metoda tf.random działa\n",
    "# w sposób podobny do tego co stworzyliśmy na poprzednim arkuszu (zmienna 'init_range'). Szczegółowo o niej później.\n",
    "# Kształty zmiennych są rzecz jasne takie same jak w zeszycie 1, bo wynikają z tej samej logiki.\n",
    "weights = tf.Variable(tf.random_uniform([input_size,output_size], minval=-0.1, maxval = 0.1))\n",
    "biases = tf.Variable(tf.random_uniform([output_size], minval=-0.1, maxval = 0.1))\n",
    "\n",
    "# Tworzymy zmienne wyjściowe. Metoda tf.matmul działa na podobnej zasadzie do użytego w zeszycie 1\n",
    "# Iloczynu Skalarnego (metoda np.dot - ang. \"dot product\"), ale jest zgeneralizowana do tensorów.\n",
    "# Tak samo w nawiasie wstawiamy tam to co chcemy przez siebie przemnożyć.\n",
    "outputs = tf.matmul(inputs,weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Deklaracja Funkcji Celu*, oraz metody optymalizacji\n",
    "\n",
    "\n",
    "*in. f. straty [podobnej 'L2' użyliśmy w zeszycie 1] - ang. Objective Function\n",
    "\n",
    "Więcej w temacie Funkcji Celu pod: https://pl.wikipedia.org/wiki/Funkcja_celowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deklarujemy strukturę funkcji straty dla normy L2 tak jak w Zeszycie 1.\n",
    "# W TF jest biblioteka takich funkcji 'tf.losses' z której wybieramy\n",
    "# interesującą nas norma L2 (euklidesowa**) jest tam pod hasłem 'mean_squared_error'.\n",
    "# Atrybutem pierwszym jest 'labels' reprezentujące klucz prawidłowych odpowiedzi dla uczenia się\n",
    "# funkcji. Np \"1\" jeśli na danym \"obrazku\" widnieje \"1\" a funkcja ma kilka odpowiedzi do wyboru.\n",
    "# Drugi atrybut to 'predictions' - logicznie są to dane wyjściowe, czyli wyniki zgadywania naszego modelu.\n",
    "# Kropka po cyfrze 2 jest tam celowo, żeby na pewno otrzymać w wyniku liczbę typu float.\n",
    "if loss_switch is True:\n",
    "    mean_loss = tf.losses.mean_squared_error(labels=targets, predictions=outputs) / 2.\n",
    "    # Funkcja Euklidesowa (\"czystsze\" dane, bez 'obserwacji_odstających')\n",
    "else:                                                                               \n",
    "    mean_loss = tf.losses.huber_loss(labels=targets, predictions=outputs) / 2.         \n",
    "    # Funkcja Hubera (dobrze radzi sobie z 'odstającymi' obserwacjami w danych)\n",
    "# Ustaw przełącznik 'switch' na panelu TensorFlow na True Jeśli chcesz Euklidesa, lub False, jeśli chcesz Hubera.\n",
    "# Więcej o tym przełączniku dowiesz się jak zjedziesz na sam koniec tego zeszytu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** O normach, w tym Euklidesowej: https://pl.wikipedia.org/wiki/Przestrze%C5%84_unormowana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deklarujemy metodę optymalizacji (treningu) funkcji. Z zasobów metod 'tf.train' wybieramy tę co ostatnio\n",
    "# czyli metodę gradientu prostego** (GradientDescentOptimizer), oraz ustalamy tempo uczenia się modelu (learning_rate)\n",
    "# Do podfunkcji '.minimize' podstawiamy ustaloną wyżej funkcję straty (mean_loss).\n",
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** O Metodzie gradientu prostego: https://pl.wikipedia.org/wiki/Metoda_gradientu_prostego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Przygotowanie do wykonywania zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kanonicznie 'sess' jest zmienną, którą nazywa się sesję TF. Tak jak w Klasach używa się self. Dla klarowności.\n",
    "# Obiekty biblioteki tf nie podlegają automatycznemu wykonywaniu wynikającemu z kolejności jak to bywa w Pythonie.\n",
    "# Jest to użyteczne ze względu na specyfikę uczenia maszynowego, o czym przekonasz się wkrótce.\n",
    "# Wywołanie sesji jest jednoznaczne z wykonaniem zadań TF. Raz wywołana, sesja jest aktywna do czasu zamknięcia\n",
    "# Bądź też zamyka się automatycznie, jeśli użyjemy jej w odpowiedniej strukturze (Zeszyt badań 2a)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Inicjalizacja zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To jest ta klasyczna część właściwie każdego skryptu TF - Inicjalizator zmiennych\n",
    "# W poprzednich wersjach TF nazywał się inaczej, jednak działa tak samo. (por. Zeszyt badań 2)\n",
    "# W tym momencie przypisujemy go do zmiennej 'initializer' żeby łatwiej później go wywołać w sesji.\n",
    "initializer = tf.global_variables_initializer()\n",
    "\n",
    "# W tym miejscu wywołujemy zdefiniowane wcześniej, zainicjowane zmienne.\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Wczytywanie danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przypisujemy wygenerowane wcześniej w NumPy dane w formacie .npz do zmiennej 'training_data'\n",
    "# za pomocą np.load - zauważ, że to co NumPy kodował, teraz rozkodowuje.\n",
    "# Ta metoda ładuje plik z tego samego miejsca w którym znajduje się skrypt,\n",
    "# chyba, że podasz inną ścieżkę.\n",
    "training_data = np.load('My_Nums.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712.349\n",
      "470.26535\n",
      "110.02011\n",
      "67.95791\n",
      "61.110386\n",
      "58.237835\n",
      "55.888\n",
      "53.676384\n",
      "51.557323\n",
      "49.522694\n",
      "47.568695\n",
      "45.692062\n",
      "43.88974\n",
      "42.15879\n",
      "40.49636\n",
      "38.899788\n",
      "37.36637\n",
      "35.89372\n",
      "34.47935\n",
      "33.120983\n",
      "31.81643\n",
      "30.563494\n",
      "29.360176\n",
      "28.204506\n",
      "27.0946\n",
      "26.028625\n",
      "25.004883\n",
      "24.02166\n",
      "23.077347\n",
      "22.170458\n",
      "21.299446\n",
      "20.462954\n",
      "19.659563\n",
      "18.887985\n",
      "18.146948\n",
      "17.435268\n",
      "16.751757\n",
      "16.095308\n",
      "15.464857\n",
      "14.859365\n",
      "14.277842\n",
      "13.719344\n",
      "13.182966\n",
      "12.667822\n",
      "12.173079\n",
      "11.69792\n",
      "11.241574\n",
      "10.803307\n",
      "10.382376\n",
      "9.97813\n",
      "9.589879\n",
      "9.217002\n",
      "8.858886\n",
      "8.514953\n",
      "8.184634\n",
      "7.8673987\n",
      "7.5627217\n",
      "7.27011\n",
      "6.989083\n",
      "6.7191806\n",
      "6.4599733\n",
      "6.211022\n",
      "5.9719286\n",
      "5.742303\n",
      "5.5217686\n",
      "5.3099656\n",
      "5.1065507\n",
      "4.911187\n",
      "4.7235637\n",
      "4.543363\n",
      "4.3703003\n",
      "4.2040906\n",
      "4.044462\n",
      "3.8911572\n",
      "3.7439163\n",
      "3.6025076\n",
      "3.4666953\n",
      "3.336265\n",
      "3.210993\n",
      "3.0906816\n",
      "2.9751413\n",
      "2.8641698\n",
      "2.7575936\n",
      "2.6552372\n",
      "2.5569293\n",
      "2.4625182\n",
      "2.371846\n",
      "2.2847638\n",
      "2.201129\n",
      "2.1208062\n",
      "2.0436628\n",
      "1.969573\n",
      "1.8984184\n",
      "1.8300786\n",
      "1.764449\n",
      "1.7014114\n",
      "1.640875\n",
      "1.5827339\n",
      "1.5268934\n",
      "1.4732661\n"
     ]
    }
   ],
   "source": [
    "# Ustalamy ilość iteracji. Kanonicznie jest to 'e', dla 'epoki' (ang. 'epoch')\n",
    "# Dla maszyny każda kolejna iteracja w której się uczy to właśnie 'epoka'.\n",
    "for e in range(iterations):\n",
    "    # Pętla zwraca wartość dla operacji 'optimize', oraz 'mean_loss' - Patrz. pkt.4 \"Deklaracja Funkcji Celu\",\n",
    "    # dla każdej 'epoki' tzn. 'None' dla 'optimize', do czego stosujemy '_', żeby zignorować tę wartość,\n",
    "    # oraz 'curr_loss' (ang. 'current loss' - aktualna strata) dla funkcji straty 'mean_loss'.\n",
    "    _, curr_loss = sess.run([optimize, mean_loss],\n",
    "                            # Logika sess.run jest taka, że w pierwszym parametrze podstawiamy listę [w, nawiasach_kwadratowych]\n",
    "                            # tych rzeczy, które chcemy, aby zostały wykonane,\n",
    "                           feed_dict = {inputs: training_data['inputs'], targets: training_data['targets']})\n",
    "                            # zaś drugi parametr, feed_dict to słownik z którego czerpie algorytm.\n",
    "                            # Składnia: feed_dict = {podstawnik1 : dane, podstawnik2 : dane},\n",
    "                            # Logika działa tu w naszym wypadku następująco: \"Weż dane opisane jako 'inputs' ze zmiennej training_data\n",
    "                            # i przypisz je do podstawnika 'inputs'. Potem weź dane opisane jako 'targets' ze zmiennej training_data\n",
    "                            # i przypisz je do podstawnika 'targets'. Zmienna training_data to jak pamiętamy nasze dane NumPy (pkt. 7).\n",
    "  \n",
    "    print(curr_loss) #Drukuje listę funkcji celu dla wszystkich epok po kolei, dzięki czemu widzimy jak model się \"uczy\".    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wizualizacja jak w zeszycie 1 dla uwidocznienia zależności. Metoda zmienia się nieco ze względu na użycie TF.\n",
    "# Znowu, normalnie będziemy używać TensorBoard i teraz zwracam to tylko po to, żeby się wizualnie upewnić,\n",
    "# że to ten sam model. Po co TF? Bo więcej elementów pozostaje tutaj takich samych pomiędzy modelami.\n",
    "# No i w NumPy bardziej skomplikowane modele to już zdecydowanie więcej kodu...\n",
    "out = np.squeeze(sess.run([outputs],\n",
    "               feed_dict = {inputs: training_data['inputs']}))\n",
    "# Różnicą jest tutaj użycie metody np.squeeze, która pozwala uzyskać odpowiedni format danych.\n",
    "# Również w wypadku danych wyjściowych, sesja najpierw musi je obliczyć z danych wejściowych,\n",
    "# co widać po zmiennej out.\n",
    "tar = np.squeeze(training_data['targets'])\n",
    "plt.plot(out,tar)\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pobaw się parametrami - np. zmień bazę rekordów (observations) do 100 000 i zobacz co się stanie.\n",
    "\n",
    "2. Tak jak poprzednio interesującym może być dla Ciebie zmiana prędkości nauki (learning_rate).\n",
    "   Wypróbuj wartości takie jak 0.0001, 0.001, 0.1, 1 itp.\n",
    "\n",
    "3. Zmień funkcję celu. Alternatywą dla funkcji L2 przy regresji liniowej jest funkcja Hubera. Ogólnie rzecz biorąc      \n",
    "jest ona bardziej odpowiednia, gdy w próbce występują przypadki wykraczające znacznie poza skalę (ang. 'outliers'), co w wygenerowanym przez nas zestawie nie miało miejsca, ale w rzeczywiestości się zdarza. Jeśli będziesz mieć do czynienia z takim zestawem może Ci się przydać. Niestety o samej funkcji Hubera dobrego i prostego źródła w polskim internecie nie znalazłem.\n",
    "Dlaczego Huber do skrajności? Bo Norma L2 podnosi wszystkie różnice \"do kwadratu\", co daje takim kwiatkom\n",
    "duży wpływ na wynik, przez co to co nieistotne może wyglądać jak istotne.\n",
    "Odpowiednią składnią do użycia funkcji celowej Hubera jest: tf.losses.huber_loss(labels, predictions).\n",
    "Podstawiłem ją na przełączniku w punkcie 4. Przełącznik jest na panelu TensorFlow.\n",
    "\n",
    "https://pl.wikipedia.org/wiki/Statystyka_odporno%C5%9Bciowa - To jest poniekąd istotne.\n",
    "Po Angielsku szukaj \"Huber Loss\" i \"Robust Regression\" jeśli Cię to interesuje.\n",
    "\n",
    "Ogólnie jak się tym wszystkim pobawisz i przeanalizujesz, to zauważysz, że dobrze jest używać odpowiedniej funkcji do odpowiednio rozdystrybuowanych danych. Fajnie to wygląda w praktyce. A jak już masz silny sprzęt to już na pewno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
